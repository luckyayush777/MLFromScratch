============================================================
Timestamp: 2026-02-16 12:53:22
Optimization Title: Momentum(beta=0.9) + ReLU + MaxPool baseline
(this run onwards we are on float precision)
[Training Time]
Elapsed Seconds: 93.701

[Data]
Input: 1x28x28 (flattened: 784)
Classes: 10
Train Samples: 60000
Test Samples: 10000

[Hyperparameters]
Learning Rate: 0.010
Momentum Beta: 0.900
Batch Size: 64
Epochs: 3
Seed: 42

[Parallelization]
OpenMP Enabled: Yes
Threads: 4

[Model]
Layer 1: Conv2d | in_ch=1 out_ch=16 kernel=3 stride=1 padding=1
Layer 2: ReLU
Layer 3: MaxPool2d | pool=2 stride=2
Layer 4: Flatten
Layer 5: Linear | in=3136 out=256
Layer 6: ReLU
Layer 7: Linear | in=256 out=10
Layer 8: Softmax + CrossEntropy

[Final Metrics]
Completed Epochs: 3
Final Avg Loss: 0.274
Final Train Accuracy: 0.901
Final Test Accuracy: 0.893

[Epoch Logs]
Epoch 0 | Avg Loss: 0.459 | Train Acc: 0.836
  Forward: 12.833s | Backward: 14.898s | Update: 1.072s
  [Forward]  conv2d: 6.046s | relu: 4.053s | pool: 1.111s | flatten: 0.420s | fc1: 1.057s | fc2: 0.137s | loss: 0.009s
  [Backward] softmax: 0.009s | fc2: 0.042s | relu1: 0.061s | fc1: 7.446s | flatten: 0.424s | pool: 2.989s | relu2: 1.586s | conv2d: 2.342s
  [Update]   1.072s
         Test Acc: 0.862
Epoch 1 | Avg Loss: 0.315 | Train Acc: 0.888
  Forward: 12.515s | Backward: 14.542s | Update: 1.070s
  [Forward]  conv2d: 6.013s | relu: 4.070s | pool: 0.967s | flatten: 0.282s | fc1: 1.050s | fc2: 0.123s | loss: 0.009s
  [Backward] softmax: 0.009s | fc2: 0.029s | relu1: 0.050s | fc1: 7.274s | flatten: 0.280s | pool: 2.956s | relu2: 1.623s | conv2d: 2.321s
  [Update]   1.070s
         Test Acc: 0.880
Epoch 2 | Avg Loss: 0.274 | Train Acc: 0.901
  Forward: 12.567s | Backward: 14.548s | Update: 1.074s
  [Forward]  conv2d: 6.008s | relu: 4.130s | pool: 0.966s | flatten: 0.276s | fc1: 1.055s | fc2: 0.122s | loss: 0.009s
  [Backward] softmax: 0.009s | fc2: 0.028s | relu1: 0.049s | fc1: 7.270s | flatten: 0.279s | pool: 2.928s | relu2: 1.635s | conv2d: 2.350s
  [Update]   1.074s
         Test Acc: 0.893

============================================================
Timestamp: 2026-02-16 11:44:03
Optimization Title: Momentum(beta=0.9) + ReLU + MaxPool baseline

[Training Time]
Elapsed Seconds: 99.252

[Data]
Input: 1x28x28 (flattened: 784)
Classes: 10
Train Samples: 60000
Test Samples: 10000

[Hyperparameters]
Learning Rate: 0.010
Momentum Beta: 0.900
Batch Size: 64
Epochs: 3
Seed: 42

[Parallelization]
OpenMP Enabled: Yes
Threads: 4

[Model]
Layer 1: Conv2d | in_ch=1 out_ch=16 kernel=3 stride=1 padding=1
Layer 2: ReLU
Layer 3: MaxPool2d | pool=2 stride=2
Layer 4: Flatten
Layer 5: Linear | in=3136 out=256
Layer 6: ReLU
Layer 7: Linear | in=256 out=10
Layer 8: Softmax + CrossEntropy

[Final Metrics]
Completed Epochs: 3
Final Avg Loss: 0.274
Final Train Accuracy: 0.901
Final Test Accuracy: 0.894

[Epoch Logs]
Epoch 0 | Avg Loss: 0.459 | Train Acc: 0.837
  Forward: 11.487s | Backward: 17.222s | Update: 1.117s
  [Forward]  conv2d: 6.278s | relu: 1.120s | pool: 1.274s | flatten: 0.504s | fc1: 2.243s | fc2: 0.060s | loss: 0.007s
  [Backward] softmax: 0.007s | fc2: 0.066s | relu1: 0.083s | fc1: 8.304s | flatten: 0.523s | pool: 3.612s | relu2: 2.204s | conv2d: 2.424s
  [Update]   1.117s
         Test Acc: 0.862
Epoch 1 | Avg Loss: 0.314 | Train Acc: 0.888
  Forward: 11.494s | Backward: 17.094s | Update: 1.113s
  [Forward]  conv2d: 6.305s | relu: 1.128s | pool: 1.269s | flatten: 0.505s | fc1: 2.246s | fc2: 0.034s | loss: 0.007s
  [Backward] softmax: 0.006s | fc2: 0.037s | relu1: 0.056s | fc1: 8.270s | flatten: 0.522s | pool: 3.592s | relu2: 2.252s | conv2d: 2.359s
  [Update]   1.113s
         Test Acc: 0.878
Epoch 2 | Avg Loss: 0.274 | Train Acc: 0.901
  Forward: 11.513s | Backward: 17.035s | Update: 1.105s
  [Forward]  conv2d: 6.324s | relu: 1.135s | pool: 1.274s | flatten: 0.504s | fc1: 2.236s | fc2: 0.033s | loss: 0.007s
  [Backward] softmax: 0.006s | fc2: 0.036s | relu1: 0.055s | fc1: 8.245s | flatten: 0.521s | pool: 3.577s | relu2: 2.253s | conv2d: 2.343s
  [Update]   1.105s
         Test Acc: 0.894

============================================================
Timestamp: 2026-02-16 11:37:04
Optimization Title: Momentum(beta=0.9) + ReLU + MaxPool baseline

[Training Time]
Elapsed Seconds: 288.273

[Data]
Input: 1x28x28 (flattened: 784)
Classes: 10
Train Samples: 60000
Test Samples: 10000

[Hyperparameters]
Learning Rate: 0.010
Momentum Beta: 0.900
Batch Size: 64
Epochs: 3
Seed: 42

[Parallelization]
OpenMP Enabled: Yes
Threads: 4

[Model]
Layer 1: Conv2d | in_ch=1 out_ch=16 kernel=3 stride=1 padding=1
Layer 2: ReLU
Layer 3: MaxPool2d | pool=2 stride=2
Layer 4: Flatten
Layer 5: Linear | in=3136 out=256
Layer 6: ReLU
Layer 7: Linear | in=256 out=10
Layer 8: Softmax + CrossEntropy

[Final Metrics]
Completed Epochs: 3
Final Avg Loss: 0.274
Final Train Accuracy: 0.901
Final Test Accuracy: 0.894

[Epoch Logs]
Epoch 0 | Avg Loss: 0.459 | Train Acc: 0.837
  Forward: 11.914s | Backward: 82.455s | Update: 1.150s
  [Forward]  conv2d: 6.543s | relu: 1.136s | pool: 1.317s | flatten: 0.511s | fc1: 2.339s | fc2: 0.061s | loss: 0.007s
  [Backward] softmax: 0.006s | fc2: 0.267s | relu1: 0.084s | fc1: 73.136s | flatten: 0.527s | pool: 3.697s | relu2: 2.219s | conv2d: 2.520s
  [Update]   1.150s
         Test Acc: 0.862
Epoch 1 | Avg Loss: 0.314 | Train Acc: 0.888
  Forward: 11.420s | Backward: 78.906s | Update: 1.080s
  [Forward]  conv2d: 6.256s | relu: 1.103s | pool: 1.264s | flatten: 0.495s | fc1: 2.258s | fc2: 0.036s | loss: 0.007s
  [Backward] softmax: 0.006s | fc2: 0.235s | relu1: 0.058s | fc1: 69.952s | flatten: 0.506s | pool: 3.579s | relu2: 2.209s | conv2d: 2.361s
  [Update]   1.080s
         Test Acc: 0.878
Epoch 2 | Avg Loss: 0.274 | Train Acc: 0.901
  Forward: 11.507s | Backward: 78.752s | Update: 1.085s
  [Forward]  conv2d: 6.286s | relu: 1.117s | pool: 1.274s | flatten: 0.499s | fc1: 2.291s | fc2: 0.034s | loss: 0.007s
  [Backward] softmax: 0.006s | fc2: 0.231s | relu1: 0.055s | fc1: 69.858s | flatten: 0.505s | pool: 3.542s | relu2: 2.219s | conv2d: 2.337s
  [Update]   1.085s
         Test Acc: 0.894

============================================================
Timestamp: 2026-02-16 11:29:02
Optimization Title: Momentum(beta=0.9) + ReLU + MaxPool baseline

[Training Time]
Elapsed Seconds: 431.882

[Data]
Input: 1x28x28 (flattened: 784)
Classes: 10
Train Samples: 60000
Test Samples: 10000

[Hyperparameters]
Learning Rate: 0.010
Momentum Beta: 0.900
Batch Size: 64
Epochs: 3
Seed: 42

[Parallelization]
OpenMP Enabled: Yes
Threads: 1

[Model]
Layer 1: Conv2d | in_ch=1 out_ch=16 kernel=3 stride=1 padding=1
Layer 2: ReLU
Layer 3: MaxPool2d | pool=2 stride=2
Layer 4: Flatten
Layer 5: Linear | in=3136 out=256
Layer 6: ReLU
Layer 7: Linear | in=256 out=10
Layer 8: Softmax + CrossEntropy

[Final Metrics]
Completed Epochs: 3
Final Avg Loss: 0.274
Final Train Accuracy: 0.901
Final Test Accuracy: 0.894

[Epoch Logs]
Epoch 0 | Avg Loss: 0.459 | Train Acc: 0.837
  Forward: 16.114s | Backward: 91.709s | Update: 1.139s
  [Forward]  conv2d: 6.241s | relu: 1.055s | pool: 1.248s | flatten: 0.489s | fc1: 6.995s | fc2: 0.079s | loss: 0.007s
  [Backward] softmax: 0.006s | fc2: 0.268s | relu1: 0.083s | fc1: 75.924s | flatten: 0.609s | pool: 3.544s | relu2: 2.202s | conv2d: 9.073s
  [Update]   1.139s
         Test Acc: 0.862
Epoch 1 | Avg Loss: 0.314 | Train Acc: 0.888
  Forward: 16.065s | Backward: 91.626s | Update: 1.133s
  [Forward]  conv2d: 6.208s | relu: 1.049s | pool: 1.241s | flatten: 0.487s | fc1: 6.991s | fc2: 0.083s | loss: 0.007s
  [Backward] softmax: 0.006s | fc2: 0.261s | relu1: 0.083s | fc1: 75.817s | flatten: 0.607s | pool: 3.519s | relu2: 2.234s | conv2d: 9.099s
  [Update]   1.133s
         Test Acc: 0.878
Epoch 2 | Avg Loss: 0.274 | Train Acc: 0.901
  Forward: 17.159s | Backward: 99.004s | Update: 1.186s
  [Forward]  conv2d: 6.705s | relu: 1.079s | pool: 1.333s | flatten: 0.509s | fc1: 7.438s | fc2: 0.088s | loss: 0.007s
  [Backward] softmax: 0.006s | fc2: 0.284s | relu1: 0.085s | fc1: 82.259s | flatten: 0.637s | pool: 3.629s | relu2: 2.256s | conv2d: 9.848s
  [Update]   1.186s
         Test Acc: 0.894

============================================================
Timestamp: 2026-02-16 00:14:21
Optimization Title: Momentum(beta=0.9) + ReLU + MaxPool baseline

[Training Time]
Elapsed Seconds: 829.761

[Data]
Input: 1x28x28 (flattened: 784)
Classes: 10
Train Samples: 60000
Test Samples: 10000

[Hyperparameters]
Learning Rate: 0.010
Momentum Beta: 0.900
Batch Size: 64
Epochs: 3
Seed: 42

[Parallelization]
OpenMP Enabled: Yes
Threads: 1

[Model]
Layer 1: Conv2d | in_ch=1 out_ch=16 kernel=3 stride=1 padding=1
Layer 2: ReLU
Layer 3: MaxPool2d | pool=2 stride=2
Layer 4: Flatten
Layer 5: Linear | in=3136 out=256
Layer 6: ReLU
Layer 7: Linear | in=256 out=10
Layer 8: Softmax + CrossEntropy

[Final Metrics]
Completed Epochs: 3
Final Avg Loss: 0.274
Final Train Accuracy: 0.901
Final Test Accuracy: 0.894

[Epoch Logs]
Epoch 0 | Avg Loss: 0.459 | Train Acc: 0.837
  Forward: 104.642s | Backward: 148.500s | Update: 1.202s
         Test Acc: 0.862
Epoch 1 | Avg Loss: 0.314 | Train Acc: 0.888
  Forward: 108.111s | Backward: 164.082s | Update: 1.294s
         Test Acc: 0.878
Epoch 2 | Avg Loss: 0.274 | Train Acc: 0.901
  Forward: 102.574s | Backward: 140.364s | Update: 1.126s
         Test Acc: 0.894

============================================================
Timestamp: 2026-02-15 23:51:42
Optimization Title: Momentum(beta=0.9) + ReLU + MaxPool baseline

[Training Time]
Elapsed Seconds: 779.673

[Data]
Input: 1x28x28 (flattened: 784)
Classes: 10
Train Samples: 60000
Test Samples: 10000

[Hyperparameters]
Learning Rate: 0.010
Momentum Beta: 0.900
Batch Size: 64
Epochs: 3
Seed: 42

[Parallelization]
OpenMP Enabled: Yes
Threads: 1

[Model]
Layer 1: Conv2d | in_ch=1 out_ch=16 kernel=3 stride=1 padding=1
Layer 2: ReLU
Layer 3: MaxPool2d | pool=2 stride=2
Layer 4: Flatten
Layer 5: Linear | in=3136 out=256
Layer 6: ReLU
Layer 7: Linear | in=256 out=10
Layer 8: Softmax + CrossEntropy

[Final Metrics]
Completed Epochs: 3
Final Avg Loss: 0.274
Final Train Accuracy: 0.901
Final Test Accuracy: 0.894

[Epoch Logs]
Epoch 0 | Avg Loss: 0.459 | Train Acc: 0.837
  Forward: 102.350s | Backward: 139.379s | Update: 1.107s
         Test Acc: 0.862
Epoch 1 | Avg Loss: 0.314 | Train Acc: 0.888
  Forward: 102.163s | Backward: 138.730s | Update: 1.089s
         Test Acc: 0.878
Epoch 2 | Avg Loss: 0.274 | Train Acc: 0.901
  Forward: 102.196s | Backward: 139.504s | Update: 1.105s
         Test Acc: 0.894

============================================================
Timestamp: 2026-02-15 23:08:56
Optimization Title: Momentum(beta=0.9) + ReLU + MaxPool baseline

[Training Time]
Elapsed Seconds: 780.145

[Data]
Input: 1x28x28 (flattened: 784)
Classes: 10
Train Samples: 60000
Test Samples: 10000

[Hyperparameters]
Learning Rate: 0.010
Momentum Beta: 0.900
Batch Size: 64
Epochs: 3
Seed: 42

[Parallelization]
OpenMP Enabled: Yes
Threads: 4

[Model]
Layer 1: Conv2d | in_ch=1 out_ch=16 kernel=3 stride=1 padding=1
Layer 2: ReLU
Layer 3: MaxPool2d | pool=2 stride=2
Layer 4: Flatten
Layer 5: Linear | in=3136 out=256
Layer 6: ReLU
Layer 7: Linear | in=256 out=10
Layer 8: Softmax + CrossEntropy

[Final Metrics]
Completed Epochs: 3
Final Avg Loss: 0.274
Final Train Accuracy: 0.901
Final Test Accuracy: 0.894

[Epoch Logs]
Epoch 0 | Avg Loss: 0.459 | Train Acc: 0.837
  Forward: 106.074s | Backward: 135.726s | Update: 1.150s
         Test Acc: 0.862
Epoch 1 | Avg Loss: 0.314 | Train Acc: 0.888
  Forward: 105.573s | Backward: 136.183s | Update: 1.148s
         Test Acc: 0.878
Epoch 2 | Avg Loss: 0.274 | Train Acc: 0.901
  Forward: 105.805s | Backward: 135.602s | Update: 1.147s
         Test Acc: 0.894

============================================================
Timestamp: 2026-02-15 16:01:26
Optimization Title: Momentum(beta=0.9) + ReLU + MaxPool baseline

[Training Time]
Elapsed Seconds: 1236.305

[Data]
Input: 1x28x28 (flattened: 784)
Classes: 10
Train Samples: 60000
Test Samples: 10000

[Hyperparameters]
Learning Rate: 0.010
Momentum Beta: 0.900
Batch Size: 64
Epochs: 3
Seed: 42

[Parallelization]
OpenMP Enabled: Yes
Threads: 4

[Model]
Layer 1: Conv2d | in_ch=1 out_ch=16 kernel=3 stride=1 padding=1
Layer 2: ReLU
Layer 3: MaxPool2d | pool=2 stride=2
Layer 4: Flatten
Layer 5: Linear | in=3136 out=256
Layer 6: ReLU
Layer 7: Linear | in=256 out=10
Layer 8: Softmax + CrossEntropy

[Final Metrics]
Completed Epochs: 3
Final Avg Loss: 0.274
Final Train Accuracy: 0.901
Final Test Accuracy: 0.894

[Epoch Logs]
Epoch 0 | Avg Loss: 0.459 | Train Acc: 0.837
  Forward: 117.953s | Backward: 179.476s | Update: 1.556s
         Test Acc: 0.862
Epoch 1 | Avg Loss: 0.314 | Train Acc: 0.888
  Forward: 128.113s | Backward: 233.637s | Update: 1.721s
         Test Acc: 0.878
Epoch 2 | Avg Loss: 0.274 | Train Acc: 0.901
  Forward: 132.368s | Backward: 254.281s | Update: 1.796s
         Test Acc: 0.894

============================================================
Timestamp: 2026-02-15 15:16:17
Optimization Title: Momentum(beta=0.9) + ReLU + MaxPool baseline

[Training Time]
Elapsed Seconds: 918.492

[Data]
Input: 1x28x28 (flattened: 784)
Classes: 10
Train Samples: 60000
Test Samples: 10000

[Hyperparameters]
Learning Rate: 0.010
Momentum Beta: 0.900
Batch Size: 32
Epochs: 3
Seed: 42

[Parallelization]
OpenMP Enabled: Yes
Threads: 24

[Model]
Layer 1: Conv2d | in_ch=1 out_ch=16 kernel=3 stride=1 padding=1
Layer 2: ReLU
Layer 3: MaxPool2d | pool=2 stride=2
Layer 4: Flatten
Layer 5: Linear | in=3136 out=256
Layer 6: ReLU
Layer 7: Linear | in=256 out=10
Layer 8: Softmax + CrossEntropy

[Final Metrics]
Completed Epochs: 3
Final Avg Loss: 0.247
Final Train Accuracy: 0.909
Final Test Accuracy: 0.893

[Epoch Logs]
Epoch 0 | Avg Loss: 0.422 | Train Acc: 0.848
  Forward: 125.448s | Backward: 159.590s | Update: 2.171s
         Test Acc: 0.875
Epoch 1 | Avg Loss: 0.288 | Train Acc: 0.895
  Forward: 124.853s | Backward: 158.523s | Update: 2.083s
         Test Acc: 0.891
Epoch 2 | Avg Loss: 0.247 | Train Acc: 0.909
  Forward: 124.795s | Backward: 158.567s | Update: 2.069s
         Test Acc: 0.893

============================================================
Timestamp: 2026-02-15 10:35:02
Optimization Title: Momentum(beta=0.9) + ReLU + MaxPool baseline

[Training Time]
Elapsed Seconds: 879.734

[Data]
Input: 1x28x28 (flattened: 784)
Classes: 10
Train Samples: 60000
Test Samples: 10000

[Hyperparameters]
Learning Rate: 0.010
Momentum Beta: 0.900
Batch Size: 32
Epochs: 3
Seed: 42

[Model]
Layer 1: Conv2d | in_ch=1 out_ch=16 kernel=3 stride=1 padding=1
Layer 2: ReLU
Layer 3: MaxPool2d | pool=2 stride=2
Layer 4: Flatten
Layer 5: Linear | in=3136 out=256
Layer 6: ReLU
Layer 7: Linear | in=256 out=10
Layer 8: Softmax + CrossEntropy

[Final Metrics]
Completed Epochs: 3
Final Avg Loss: 0.247
Final Train Accuracy: 0.909
Final Test Accuracy: 0.893

[Epoch Logs]
Epoch 0 | Avg Loss: 0.422 | Train Acc: 0.848
  Forward: 109.654s | Backward: 159.514s | Update: 2.593s
         Test Acc: 0.875
Epoch 1 | Avg Loss: 0.288 | Train Acc: 0.895
  Forward: 109.791s | Backward: 157.116s | Update: 2.639s
         Test Acc: 0.891
Epoch 2 | Avg Loss: 0.247 | Train Acc: 0.909
  Forward: 112.689s | Backward: 167.197s | Update: 2.786s
         Test Acc: 0.893

============================================================
Timestamp: 2026-02-15 09:47:22
Optimization Title: Momentum(beta=0.9) + ReLU + MaxPool baseline

[Training Time]
Elapsed Seconds: 1017.202

[Data]
Input: 1x28x28 (flattened: 784)
Classes: 10
Train Samples: 60000
Test Samples: 10000

[Hyperparameters]
Learning Rate: 0.010
Momentum Beta: 0.900
Batch Size: 32
Epochs: 3
Seed: 42

[Model]
Layer 1: Conv2d | in_ch=1 out_ch=16 kernel=3 stride=1 padding=1
Layer 2: ReLU
Layer 3: MaxPool2d | pool=2 stride=2
Layer 4: Flatten
Layer 5: Linear | in=3136 out=256
Layer 6: ReLU
Layer 7: Linear | in=256 out=10
Layer 8: Softmax + CrossEntropy

[Final Metrics]
Completed Epochs: 3
Final Avg Loss: 0.247
Final Train Accuracy: 0.909
Final Test Accuracy: 0.893

[Epoch Logs]
Epoch 0 | Avg Loss: 0.422 | Train Acc: 0.848
  Forward: 112.653s | Backward: 174.665s | Update: 2.584s
         Test Acc: 0.875
Epoch 1 | Avg Loss: 0.288 | Train Acc: 0.895
  Forward: 110.254s | Backward: 165.231s | Update: 2.558s
         Test Acc: 0.891
Epoch 2 | Avg Loss: 0.247 | Train Acc: 0.909
  Forward: 130.325s | Backward: 251.456s | Update: 3.534s
         Test Acc: 0.893

